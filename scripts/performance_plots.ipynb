{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "from __future__ import division, print_function\n",
    "\n",
    "from perf_plotter import get_filtered_data, flatten, get_diffs, __compare, rgetattr\n",
    "import data_parser\n",
    "import argparse\n",
    "import plot_styles as ps\n",
    "from plot_styles import wheeler, marker_wheel, color_wheel\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "import general_plotting as gp\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from optionloop import OptionLoop\n",
    "from collections import defaultdict\n",
    "import six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = data_parser.run\n",
    "rundata = data_parser.rundata\n",
    "mechdata = data_parser.mechdata\n",
    "data = None\n",
    "try:\n",
    "    with open(os.path.join('.', 'data.pickle'), 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    if data is None:\n",
    "        data = data_parser.parse_data()\n",
    "        with open(os.path.join('.', 'data.pickle'), 'wb') as file:\n",
    "            pickle.dump(data, file)\n",
    "            \n",
    "mechs = data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(data, plot_type='runtime', norm=True, plot_condition_scaling=False, plot_cores=False,\n",
    "             plot_simd=False, return_diffs=False, **pwkwds):\n",
    "    diffs, locs, check = get_diffs(flatten(data))\n",
    "    def __eliminate(diff, fail=True):\n",
    "        ind = next((i for i in range(len(locs)) if check[locs[i]] == diff), None)\n",
    "        if not fail and ind is None:\n",
    "            return\n",
    "        diffs.pop(ind)\n",
    "        locs.pop(ind)\n",
    "    if plot_condition_scaling or plot_cores or plot_simd:\n",
    "        diffs.append(set(data.keys()))\n",
    "        locs.append(-1)\n",
    "        check.append('mechdata.name')\n",
    "    if plot_cores:\n",
    "        __eliminate('cores')\n",
    "        \n",
    "    oploop = OptionLoop({check[locs[i]]: list(diffs[i]) for i in range(len(locs))})\n",
    "    rv = []\n",
    "    for state in oploop:\n",
    "        subdata = get_filtered_data(data, warn=False, strict=True, **state)\n",
    "        subdata = flatten(subdata)\n",
    "        if not subdata:\n",
    "            continue\n",
    "        x, y, z = gp.process_data(subdata, plot_type, plot_condition_scaling=plot_condition_scaling,\n",
    "                                  plot_cores=plot_cores, **pwkwds)\n",
    "        # get the part of the subdata that is identical across all for later ident.\n",
    "        sd, _, sc = get_diffs(subdata)\n",
    "        # and store\n",
    "        same = {c: rgetattr(subdata[0], c) for c in sc if sc not in sd}\n",
    "        if plot_condition_scaling or plot_cores or plot_simd:\n",
    "            same['mechdata.name'] = state['mechdata.name']\n",
    "        rv.append((same, (np.array(x), np.array(y), np.array(z)), subdata))\n",
    "    if return_diffs:\n",
    "        return rv, [check[loc] for loc in locs]\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(datalist):\n",
    "    combined = defaultdict(lambda: [])\n",
    "    for data in datalist:\n",
    "        for mech in data:\n",
    "            combined[mech].extend(data[mech])\n",
    "\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class normalizer(object):\n",
    "    def __init__(self, key):\n",
    "        self.ymax = defaultdict(lambda: None)\n",
    "        if isinstance(key, list):\n",
    "            key = tuple(key)\n",
    "        self.key = key\n",
    "    \n",
    "    def __getitem__(self, state):\n",
    "        if self.key is None:\n",
    "            return self.ymax['default']\n",
    "        elif isinstance(self.key, tuple):\n",
    "            return self.ymax[tuple(state[k] for k in self.key)]\n",
    "        return self.ymax[state[self.key]]\n",
    "\n",
    "    def __setitem__(self, state, value):\n",
    "        if self.key is None:\n",
    "            self.ymax['default'] = value\n",
    "        elif isinstance(self.key, tuple):\n",
    "            self.ymax[tuple(state[k] for k in self.key)] = value\n",
    "        else:\n",
    "            self.ymax[state[self.key]] = value\n",
    "            \n",
    "class core_norm(normalizer):\n",
    "    def __init__(self, _):\n",
    "        super(core_norm, self).__init__('cores')\n",
    "        \n",
    "    def select(self, arr):\n",
    "        return arr[0]\n",
    "        \n",
    "    def __setitem__(self, state, value):\n",
    "        if self.key is None:\n",
    "            self.ymax['default'] = self.select(value)\n",
    "        else:\n",
    "            self.ymax[state[self.key]] = self.select(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_per_key(data, key):\n",
    "    # normalize pre-separated data per a given key in the data\n",
    "    # first pass -- get y max per x\n",
    "    ymax = normalizer(key)\n",
    "    op = np.maximum\n",
    "    for state, (x, y, z), _ in data:\n",
    "        if ymax[state] is None:\n",
    "            ymax[state] = y[:]\n",
    "        def __appended(current, desired):\n",
    "            diff = desired.shape[0] - current.shape[0]\n",
    "            return np.hstack((current, np.zeros(diff)))\n",
    "        if y.shape[0] < ymax[state].shape[0]:\n",
    "            # missing dat\n",
    "            y = __appended(y, ymax[state])\n",
    "        elif y.shape[0] > ymax[state].shape[0]:\n",
    "            ymax[state] = __appended(ymax[state], y)\n",
    "        ymax[state] = op(y, ymax[state])\n",
    "        \n",
    "    # second pass -- normalize y & z\n",
    "    for i in range(len(data)):\n",
    "        state = data[i][0]\n",
    "        x, y, z = data[i][1]\n",
    "        z = (z / y) * (ymax[state][:y.shape[0]] / y)\n",
    "        y = ymax[state][:y.shape[0]] / y\n",
    "        data[i] = (state, (x, y, z), data[i][2])\n",
    "   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_per_mech(data):\n",
    "    # normalize pre-separated data per mechanism\n",
    "    return normalize_per_key(data, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data, namefunc, markerfunc, norm=None, stats=False, **pwargs):\n",
    "    plotfun = pwargs.pop('plotfun', gp.plot)\n",
    "    sep = separate(data, return_diffs=stats, **pwargs)\n",
    "    diffs = None\n",
    "    if stats:\n",
    "        sep, diffs = sep\n",
    "        diffs = name_order(diffs, False)\n",
    "    if norm is not None:\n",
    "        sep = norm(sep)\n",
    "    plot_ind = 0\n",
    "    for state, subdata, runs in sep:\n",
    "        if stats:\n",
    "            def stringify(r):\n",
    "                if diffs:\n",
    "                    return ', '.join(['{}={}'.format(d, rgetattr(r, d)) for d in diffs])\n",
    "                else:\n",
    "                    return state\n",
    "            print(stringify(runs[0]), [x for  x in zip(subdata[0], subdata[1])])\n",
    "        plotfun(*subdata, label=namefunc(state), marker=markerfunc(state), plot_ind=plot_ind)\n",
    "        plot_ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_name(state, key):\n",
    "    return ps.pretty_names(key).format(state[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter orderings -- to ensure the legend always contains the same\n",
    "# parameter -> symbol / color mapping\n",
    "vectype_order = ['w', 'd', 'par', 'openmp']\n",
    "descriptor_order = ['haswell', 'srv2', 'v1']\n",
    "gpu_desc_order = ['gpu', 'srv2-gpu', 'v1-gpu']\n",
    "vecwidth_order = ['4', '8', '16']\n",
    "gpu_vecwidth_order = ['64', '128']\n",
    "conp_order = ['conp', 'conv']\n",
    "data_order = ['C', 'F']\n",
    "mech_order = ['H2', 'CH4', 'C2H4', 'IC5H11OH']\n",
    "sparse_order = ['sparse', 'full']\n",
    "jac_order = ['jac', 'fdjac']\n",
    "platform_order = ['hpc', 'srv2', 'v1']\n",
    "\n",
    "# common labels\n",
    "reac_label = r'Number of Reactions'\n",
    "cores_label = r'Number of CPU Cores'\n",
    "states_label = r'Number of Conditions'\n",
    "speedup_label = r'Speedup'\n",
    "efficiency_label = r'$\\varepsilon$'\n",
    "simd_efficiency_label = r'$\\varepsilon_{\\text{SIMD}}$'\n",
    "runtime_label = r'Run time (\\si{\\milli\\second} / state)'\n",
    "\n",
    "# and some common legend locations\n",
    "ll_mid_right = dict(loc='upper right', bbox_to_anchor=(0.92, 0.62))\n",
    "legend_top = dict(bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\",\n",
    "                  mode=\"expand\", borderaxespad=0, ncol=2)\n",
    "ll_mid_right_long = dict(loc='upper right', bbox_to_anchor=(0.92, 0.72))\n",
    "ll_mid_righter_long = dict(loc='upper right', bbox_to_anchor=(0.95, 0.72))\n",
    "\n",
    "from os import getcwd\n",
    "from os.path import dirname, join\n",
    "figpath = join(dirname(getcwd()), 'figures')\n",
    "\n",
    "def name_order(param_list, istup=True):\n",
    "    fields = run._fields + tuple('mechdata.' + x for x in mechdata._fields)\n",
    "    return sorted(param_list, key=lambda x: fields.index(x[0] if istup else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_plot(ylog=None, xlog=None, limits={}, labels={}, is_norm=False, figname='',\n",
    "                  legend_loc={}, legendmaker=None, plot_cores=False, tight=True,\n",
    "                  plot_simd=False, crossover=False):\n",
    "    plt.xlabel(labels.get('x', reac_label if not plot_cores else cores_label))\n",
    "    if plot_cores:\n",
    "        ylabel_default = efficiency_label if not crossover else runtime_label\n",
    "    elif plot_simd:\n",
    "        ylabel_default = simd_efficiency_label\n",
    "    else:\n",
    "        ylabel_default = speedup_label if is_norm else runtime_label\n",
    "    plt.ylabel(labels.get('y', ylabel_default))\n",
    "    if 'title' in labels:\n",
    "        plt.title(labels['title'])\n",
    "    if 'x' in limits:\n",
    "        plt.gca().set_xlim(limits['x'])\n",
    "    if 'y' in limits:\n",
    "        plt.gca().set_ylim(limits['y'])\n",
    "    if ylog:\n",
    "        ylog = ylog if ylog != True else 10\n",
    "        plt.gca().set_yscale('log', basey=ylog)\n",
    "    if xlog:\n",
    "        xlog = xlog if xlog != True else 10\n",
    "        plt.gca().set_xscale('log', basex=xlog)\n",
    "    legend = ps.legend_style.copy()\n",
    "    legend.update(legend_loc)\n",
    "    handles = legendmaker.__getlegend__()\n",
    "    if handles:\n",
    "        plt.legend(handles=handles, **legend)\n",
    "    else:\n",
    "        plt.legend(**legend)\n",
    "    # and finalize\n",
    "    ax = plt.gca()\n",
    "    # set tick size\n",
    "    plt.tick_params(axis='both', which='major', labelsize=ps.tick_font_size)\n",
    "    plt.tick_params(axis='both', which='minor', labelsize=ps.minor_tick_font_size)\n",
    "    # and label size\n",
    "    for item in (ax.title, ax.xaxis.label, ax.yaxis.label):\n",
    "        item.set_fontsize(ps.title_font_size)\n",
    "    # and set tight\n",
    "    if tight:\n",
    "        plt.tight_layout()\n",
    "\n",
    "    if figname:\n",
    "        if not figname.endswith('.pdf'):\n",
    "            figname += '.pdf'\n",
    "        plt.savefig(join(figpath, figname), bbox_inches=\"tight\")\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_standard(data, namefunc, marker_func, labels={}, ylog=False, xlog=False,\n",
    "                       limits={}, norm=None, filter_num_conditions=None,\n",
    "                       figname='', legend_loc={},\n",
    "                       **pwargs):\n",
    "    if filter_num_conditions is not None:\n",
    "        data = filter_num_conditions(data)\n",
    "    marker_func.reset()\n",
    "    crossover = pwargs.pop('crossover', False)\n",
    "    plot(data, namefunc, marker_func, norm=norm, **pwargs)\n",
    "    finalize_plot(ylog=ylog, xlog=xlog, limits=limits, labels=labels, is_norm=norm is not None,\n",
    "                  figname=figname, legend_loc=legend_loc, legendmaker=marker_func,\n",
    "                  plot_cores=pwargs.get('plot_cores', False),\n",
    "                  plot_simd=pwargs.get('plot_simd', False),\n",
    "                  crossover=crossover)\n",
    "    \n",
    "def plot_data_gpu_scaling(*args, **kwargs):\n",
    "    if not 'labels' in kwargs:\n",
    "        kwargs['labels'] = {}\n",
    "    kwargs['labels']['x'] = states_label\n",
    "    plot_data_standard(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_gpu_standard(*args, **kwargs):\n",
    "    def max_num_conds_filter(data):\n",
    "        warn = False\n",
    "        for mech in data:\n",
    "            max_num_cond = max([max(r.num_conditions for r in d.rundata) for d in data[mech]])\n",
    "            for i in range(len(data[mech])):\n",
    "                local_max_num_cond = max(r.num_conditions for r in data[mech][i].rundata)\n",
    "                if local_max_num_cond != max_num_cond and not warn:\n",
    "                    warn = True\n",
    "                    print('Warning: {} does not match maximum # of conditions {} for data {}'.format(\n",
    "                          local_max_num_cond, max_num_cond, data[mech][i]))\n",
    "                copy = data[mech][i].copy()\n",
    "                data[mech][i] = copy._replace(\n",
    "                    rundata=[r for r in copy.rundata if r.num_conditions == local_max_num_cond])\n",
    "        return data\n",
    "    plot_data_standard(*args, filter_num_conditions=max_num_conds_filter, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(d, const_func=lambda state, x: 1. / x, ymin_select = lambda y: y[0]):\n",
    "    # normalize pre-separated data per a given key in the data\n",
    "    # first pass -- get y max per x\n",
    "    ymin = None\n",
    "    state, (x, y, z), _ = d\n",
    "    # minimum is assumed to be first data point (either 1 core, or unvectorized simd)\n",
    "    ymin = ymin_select(y)\n",
    "\n",
    "    # second pass -- normalize y & z\n",
    "    c = const_func(state, x)\n",
    "    z = (z / y) * (ymin * c / y)\n",
    "    y = ymin * c / y\n",
    "    # return updated\n",
    "    return (state, (x, y, z), d[2])\n",
    "\n",
    "def plot_data_scaling(*args, **kwargs):\n",
    "    kwargs['plot_cores'] = True\n",
    "    scale = kwargs.pop('scale', True)\n",
    "    if scale:\n",
    "        kwargs['norm'] = lambda data: [scaling(x) for x in data]\n",
    "    kwargs['xlog'] = 2\n",
    "    if not 'limits' in kwargs:\n",
    "        kwargs['limits'] = {}\n",
    "    if not 'x' in kwargs['limits']:\n",
    "        kwargs['limits']['x'] = (None, None)\n",
    "    kwargs['limits']['x'] = (1.8, kwargs['limits']['x'][1])\n",
    "    plot_data_standard(*args, **kwargs)\n",
    "    \n",
    "def plot_data_scaling_crossover(*args, **kwargs):\n",
    "    base = kwargs.pop('base', 'Shallow')\n",
    "    kwargs['scale'] = False\n",
    "    def plot_intercept(*subdata, label=None, marker=None, plot_ind=None):\n",
    "        if base not in label:\n",
    "            gp.plot(*subdata, label=label, marker=marker, plot_ind=plot_ind)\n",
    "        else:\n",
    "            marker, hollow, color, size = marker\n",
    "            x, y, z = subdata\n",
    "            plt.plot([x[0], x[-1] + 2], [y[0], y[0]], color=color, label='1-core')\n",
    "            plt.plot([x[0], x[-1] + 2], [y[2], y[2]], '--', color=color, label='4-cores')\n",
    "        \n",
    "    kwargs['plotfun'] = plot_intercept\n",
    "    kwargs['crossover'] = True\n",
    "    plot_data_scaling(*args, **kwargs)\n",
    "    \n",
    "def plot_data_simd(*args, **kwargs):\n",
    "    kwargs['plot_simd'] = True\n",
    "    allow_skip = kwargs.pop('allow_skip', False)\n",
    "    ideal_efficiencies = {\n",
    "        'srv2': 2.,\n",
    "        'haswell': 4.\n",
    "    }\n",
    "    def const_func(state, x):\n",
    "        return 1. if state['vectype'] == 'par' else 1. / ideal_efficiencies[state['descriptor']]\n",
    "    def norm(data):\n",
    "        for mech in mech_order:\n",
    "            # select mechanisms that match this:\n",
    "            subdata = [(i, x) for i, x in enumerate(data) if x[0]['mechdata.name'] == mech]\n",
    "            # next, select the unvectorized SIMD as the baseline\n",
    "            baseline = [d for d in subdata if d[1][0]['vectype'] == 'par']\n",
    "            if allow_skip and len(baseline) == 0:\n",
    "                continue\n",
    "            assert len(baseline) == 1, 'Multiple unvectorized data'\n",
    "            baseline = baseline[0]\n",
    "            # assert baseline[1][1][1].size == 1, 'Multiple mechanism data'\n",
    "            if baseline[1][1][1].size == 1:\n",
    "                ymin = baseline[1][1][1][0]\n",
    "                ymin_select=lambda y: ymin\n",
    "            else:\n",
    "                ymin_select=lambda y: baseline[1][1][1][:]\n",
    "            for subi, subd in subdata:\n",
    "                    data[subi] = scaling(subd, const_func=const_func, ymin_select=ymin_select)\n",
    "        return data\n",
    "                \n",
    "    kwargs['norm'] = norm\n",
    "    plot_data_standard(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class recursive_dict(object):\n",
    "    def __init__(self, key, value_list, return_index=True):\n",
    "        self.key = key\n",
    "        self.value_list = None\n",
    "        if value_list is not None:\n",
    "            self.value_list = value_list.copy()\n",
    "        self.return_index = return_index\n",
    "        \n",
    "    def __call__(self, state, **kwargs):\n",
    "        key = self.key\n",
    "        if 'key' in kwargs:\n",
    "            key = kwargs.pop('key')\n",
    "        values = self.value_list\n",
    "        if 'values' in kwargs:\n",
    "            values = kwargs.pop('values')\n",
    "        if values is None:\n",
    "            # no value list ->\n",
    "            return key\n",
    "        if isinstance(values, dict):\n",
    "            # recursively defined\n",
    "            k, v = values[state[key]]\n",
    "            return self.__call__(state, key=k, values=v)\n",
    "        if self.return_index:\n",
    "            # if we want the index\n",
    "            return values.index(state[key])\n",
    "        # else the value\n",
    "        return values[values.index(state[key])]\n",
    "\n",
    "class marker_dict(object):\n",
    "    def __init__(self, color_key, color_dict, marker_key, marker_dict,\n",
    "                 size_key=None, size_dict=None, grey=False, num_colors=2,\n",
    "                 rdict=recursive_dict, sizes=None):\n",
    "        self.color_dict = rdict(color_key, color_dict, return_index=True)\n",
    "        \n",
    "        # handle color_maps\n",
    "        cmap = 'Greys' if grey else 'inferno'\n",
    "        self.internal_color_wheel = plt.get_cmap(cmap, num_colors + 1)\n",
    "        self.color_wheel = lambda x: self.internal_color_wheel(x)\n",
    "        self.num_colors = num_colors - 1\n",
    "            \n",
    "        self.marker_dict = rdict(marker_key, marker_dict)\n",
    "        self.marker_wheel = wheeler(marker_wheel)\n",
    "        \n",
    "        if size_key is None:\n",
    "            assert size_dict is None\n",
    "            size_key = color_key\n",
    "            size_dict = color_dict\n",
    "        else:\n",
    "            assert size_dict\n",
    "            \n",
    "            \n",
    "        self.size_dict = rdict(size_key, size_dict)\n",
    "        if sizes is None:\n",
    "            sizes = num_colors\n",
    "        sizearr = [12, 16, 20, 24]\n",
    "        sizes = np.linspace(sizearr[-sizes], sizearr[-1], sizes, endpoint=True)\n",
    "        self.size_wheel = wheeler(sizes)\n",
    "    \n",
    "    def __getlegend__(self):\n",
    "        return False\n",
    "        \n",
    "    def __getcolor__(self, state):\n",
    "        ind = self.color_dict(state)\n",
    "        # assert ind <= self.num_colors\n",
    "        return tuple(self.color_wheel(ind)[:3],) + (1,)\n",
    "    \n",
    "    def __getmarker__(self, state):\n",
    "        return self.marker_wheel(self.marker_dict(state))\n",
    "    \n",
    "    def __getsize__(self, state):\n",
    "        return self.size_wheel(self.size_dict(state))\n",
    "    \n",
    "    def reset(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, state):\n",
    "        marker, hollow = self.__getmarker__(state)\n",
    "        return marker, hollow, self.__getcolor__(state), self.__getsize__(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class compound_namer(object):\n",
    "    def __normalize(self, kvdict):\n",
    "        outdict = kvdict.copy()\n",
    "        for key, values in kvdict.items():\n",
    "            if values is not None:\n",
    "                # now, for each new kv pair, ensure we have a further dictionary\n",
    "                if isinstance(values, dict):\n",
    "                    # recursively normalize\n",
    "                    outdict[key] = self.__normalize(values)\n",
    "                else:\n",
    "                    # or a (key, None) tuple\n",
    "                    outdict[key] = (values, None)\n",
    "        return outdict\n",
    "\n",
    "    def __init__(self, **kvlist):\n",
    "        self.keys = []\n",
    "        for key, values in name_order(list(self.__normalize(kvlist).items())):\n",
    "            self.keys.append(recursive_dict(key, values, False))\n",
    "                    \n",
    "    \n",
    "    def add_key(self, state, key):\n",
    "        return pretty_name(state, key(state))\n",
    "            \n",
    "    def add_keys(self, state):\n",
    "        name = ''\n",
    "        for key in self.keys:\n",
    "            if name:\n",
    "                name += ' - '\n",
    "            name += self.add_key(state, key)\n",
    "        return name\n",
    "    \n",
    "    def __call__(self, state):\n",
    "        return self.add_keys(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tracking_dict(recursive_dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(tracking_dict, self).__init__(*args, **kwargs)\n",
    "        self.maps = {}\n",
    "    \n",
    "    def __call__(self, state, **kwargs):\n",
    "        key = self.key\n",
    "        if 'key' in kwargs:\n",
    "            key = kwargs.get('key')\n",
    "        values = self.value_list\n",
    "        if 'values' in kwargs:\n",
    "            values = kwargs.get('values')\n",
    "        assert not values is None, \"Can't use with compound namer\"\n",
    "        if not isinstance(values, dict):\n",
    "            # we've reached the end of recursion\n",
    "            if self.return_index:\n",
    "                # if we want the index\n",
    "                value = values.index(state[key])\n",
    "            else:\n",
    "                # else the value\n",
    "                value = values[values.index(state[key])]\n",
    "            name = pretty_name(state, key)\n",
    "            assert state[key] not in self.maps or self.maps[state[key]] == (value, name)\n",
    "            self.maps[state[key]] = (value, name)\n",
    "        return super(tracking_dict, self).__call__(state, **kwargs)\n",
    "            \n",
    "        \n",
    "\n",
    "# an override of the marker dict that compresses legends\n",
    "class legend_handler(marker_dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        kwargs['rdict'] = tracking_dict\n",
    "        self.explicit = kwargs.pop('explicit', False)\n",
    "        self.replacements = kwargs.pop('replacements', {})\n",
    "        self.ignore = kwargs.pop('ignore', [])\n",
    "        \n",
    "        super(legend_handler, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.color_dict.maps = {}\n",
    "        self.marker_dict.maps = {}\n",
    "        self.size_dict.maps = {}\n",
    "\n",
    "    def __getlegend__(self):\n",
    "        handles = []\n",
    "        for key, (color_ind, name) in sorted(self.color_dict.maps.items(), key=lambda x: x[1][0]):\n",
    "            if name in self.ignore:\n",
    "                continue\n",
    "            handles.append(mpatches.Patch(color=self.color_wheel(color_ind),\n",
    "                                          label=self.replacements.get(name, name)))\n",
    "        for key, (marker_ind, name) in sorted(self.marker_dict.maps.items(), key=lambda x: x[1][0]):\n",
    "            if len(self.marker_dict.maps) == 1 and not self.explicit:\n",
    "                continue\n",
    "            if name in self.ignore:\n",
    "                continue\n",
    "            markersize = 15\n",
    "            if key in self.size_dict.maps:\n",
    "                markersize, _ = self.size_dict.maps[key]\n",
    "                markersize = self.size_wheel(markersize)\n",
    "            marker, hollow = self.marker_wheel(marker_ind)\n",
    "            marker_dict = {'marker': marker,\n",
    "                           'color': 'k',\n",
    "                           'markeredgecolor': 'k',\n",
    "                           'markersize': markersize}\n",
    "            if hollow:\n",
    "                marker_dict['markerfacecolor'] = 'None'\n",
    "            handles.append(mlines.Line2D([], [], linestyle='None',\n",
    "                                         label=self.replacements.get(name, name), **marker_dict))\n",
    "        return handles\n",
    "    \n",
    "class crossover_handler(legend_handler):\n",
    "    def __getlegend__(self):\n",
    "        # get default\n",
    "        handles = super(crossover_handler, self).__getlegend__()\n",
    "        # remove shallow\n",
    "        handles = [x for x in handles if x._label != 'Shallow']\n",
    "        # add 1 & 4 core count\n",
    "        handles.append(mlines.Line2D([], [], linestyle='-', label=r'Shallow - \\num{1}-core', color='k'))\n",
    "        handles.append(mlines.Line2D([], [], linestyle='--', label=r'Shallow - \\num{4}-cores', color='k'))\n",
    "        return handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class default_filters(object):\n",
    "    def __init__(self, **filters):\n",
    "        self.filters = dict(platform=lambda x: True,\n",
    "                       lang=lambda x: True,\n",
    "                       vectype=lambda x: True,\n",
    "                       cores='1',\n",
    "                       conp='conp',\n",
    "                       order=lambda x: True,\n",
    "                       vecwidth=lambda x: True,\n",
    "                       descriptor=lambda x: True,\n",
    "                       rates='hybrid')\n",
    "        self.filters.update(filters)\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        newfilt = self.filters.copy()\n",
    "        newfilt.update(other)\n",
    "        return default_filters(**newfilt)\n",
    "\n",
    "def get_filters(lang='opencl', cpu=True, vecwidth='8', source=True, sparse=True):\n",
    "    base = default_filters(rates='fixed')\n",
    "    if lang == 'opencl':\n",
    "        base += {'lang': 'opencl', 'vecwidth': vecwidth}\n",
    "    elif lang == 'c':\n",
    "        base += {'lang': 'c', 'vectype': 'openmp'}\n",
    "    if cpu is not None:\n",
    "        base += {'order': ('C' if cpu else 'F')}\n",
    "        if not cpu and vecwidth == '8':\n",
    "            # change default\n",
    "            base += {'vecwidth': '128'}\n",
    "    if source is not None:\n",
    "        base += {'rtype': ('spec' if source else 'jac')}\n",
    "        if not source:\n",
    "            base += {'sparse': 'sparse' if sparse else 'full'}\n",
    "    return base\n",
    "\n",
    "def get_filtered(base=None, **filters):\n",
    "    adata = data\n",
    "    if 'additional_data' in filters:\n",
    "        add = filters.pop('additional_data')\n",
    "        for mech in data:\n",
    "            assert not any(isinstance(x, list) for x in add[mech])\n",
    "            assert not any(isinstance(x, list) for x in data[mech])\n",
    "        adata = combine([data.copy(), add.copy()])\n",
    "    for mech in adata:\n",
    "        assert not any(isinstance(x, list) for x in adata[mech])\n",
    "    base = (base or default_filters()) + filters\n",
    "    return get_filtered_data(adata, **base.filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin source term plots\n",
    "#1 POCL equivalency over all type\n",
    "\n",
    "filtered = combine([\n",
    "    get_filtered(\n",
    "        get_filters(),\n",
    "        platform='portable',\n",
    "        descriptor=lambda x: x in ['srv2', 'haswell'],\n",
    "        vecwidth='4',\n",
    "        vectype='par',\n",
    "        strict=True),\n",
    "    get_filtered(\n",
    "        get_filters(),\n",
    "        platform='portable',\n",
    "        descriptor=lambda x: x in ['srv2', 'haswell'],\n",
    "        vectype=lambda x: x in ['d', 'w']),\n",
    "    get_filtered(\n",
    "        get_filters(lang='c'),\n",
    "        descriptor=lambda x: x in ['srv2', 'haswell'])])\n",
    "\n",
    "namer = compound_namer(descriptor=None, vectype=None)\n",
    "marker = legend_handler('descriptor', descriptor_order,\n",
    "                        'vectype', vectype_order,\n",
    "                        'vectype', vectype_order,\n",
    "                        sizes=4)\n",
    "\n",
    "plot_data_standard(filtered, namer, marker,\n",
    "    ylog=True,\n",
    "    limits={'y': [1e-3, 1e0]},\n",
    "    legend_loc=ll_mid_right_long,\n",
    "    figname='pocl_source_nonorm.pdf')\n",
    "\n",
    "plot_data_standard(filtered, namer, marker,\n",
    "    norm=lambda data: normalize_per_key(data, 'descriptor'),\n",
    "    #limits={'y': [1e-3, 1e0]},\n",
    "    legend_loc=ll_mid_right_long,\n",
    "    figname='pocl_source.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next intel vs OpenMP\n",
    "\n",
    "def __get_data(desc, vectype=['w', 'par'], include_openmp=True, openmp_only=False):\n",
    "    filtered = get_filtered(\n",
    "                       get_filters(),\n",
    "                       platform='intel',\n",
    "                       vectype=lambda x: x in vectype,\n",
    "                       descriptor=lambda x: x in desc)\n",
    "    openmp = get_filtered(\n",
    "                       get_filters(lang='c'),\n",
    "                       descriptor=lambda x: x in desc)\n",
    "    if not include_openmp:\n",
    "        return filtered\n",
    "    elif openmp_only:\n",
    "        return openmp\n",
    "    \n",
    "    return combine([filtered, openmp])\n",
    "\n",
    "namer = compound_namer(descriptor=None,\n",
    "                       vectype=None)\n",
    "marker = legend_handler(\n",
    "    'descriptor', descriptor_order,\n",
    "    'vectype', vectype_order,\n",
    "    'vectype', vectype_order,\n",
    "    sizes=4\n",
    "    )\n",
    "\n",
    "#plot_data_standard(__get_data(['srv2']), namer, marker, {\n",
    "#    'title': title + ' - SSE4.2'},\n",
    "#                   norm=normalize_per_mech)\n",
    "\n",
    "#plot_data_standard(__get_data(['haswell']), namer, marker, {\n",
    "#    'title': title + ' - AVX2'},\n",
    "#                   norm=normalize_per_mech)\n",
    "\n",
    "plot_data_standard(__get_data(['haswell', 'srv2']), namer, marker,\n",
    "                  figname='intel_source_nonorm.pdf',\n",
    "                  limits={'y': [5e-4, 1e0]},\n",
    "                  ylog=True,\n",
    "                  legend_loc=ll_mid_right)\n",
    "\n",
    "plot_data_standard(__get_data(['haswell', 'srv2']), namer, marker,\n",
    "                   norm=lambda data: normalize_per_key(data, 'descriptor'),\n",
    "                  figname='intel_source.pdf',\n",
    "                  legend_loc=ll_mid_right,\n",
    "                  stats=True)\n",
    "\n",
    "print('unvec')\n",
    "plot_data_standard(__get_data(['haswell', 'srv2'], vectype=['par'], include_openmp=False), namer, marker,\n",
    "                   norm=normalize_per_mech,\n",
    "                  legend_loc=ll_mid_right,\n",
    "                  stats=True)\n",
    "\n",
    "print('omp')\n",
    "plot_data_standard(__get_data(['haswell', 'srv2'], openmp_only=True), namer, marker,\n",
    "                   norm=normalize_per_mech,\n",
    "                  legend_loc=ll_mid_right,\n",
    "                  stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conp vs conv\n",
    "filtered = combine([get_filtered(\n",
    "                        get_filters(),\n",
    "                        platform='intel',\n",
    "                        conp=lambda x: True,\n",
    "                        descriptor='haswell'),\n",
    "                    get_filtered(\n",
    "                        get_filters(lang='c'),\n",
    "                        conp=lambda x: True,\n",
    "                        descriptor='haswell')])\n",
    "        \n",
    "\n",
    "namer = compound_namer(conp=None, vectype=None)\n",
    "marker = legend_handler(\n",
    "    'conp', conp_order,\n",
    "    'vectype', vectype_order)\n",
    "\n",
    "\n",
    "plot_data_standard(filtered, namer, marker,\n",
    "                   ylog=True,\n",
    "                   figname='source_conpvsconv.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C vs F on cpu\n",
    "filtered = combine([get_filtered(\n",
    "                        get_filters(),\n",
    "                        platform='intel',\n",
    "                        vectype='w',\n",
    "                        descriptor='haswell',\n",
    "                        order='C'),\n",
    "                    get_filtered(\n",
    "                        get_filters(),\n",
    "                        platform='intel',\n",
    "                        vectype='w',\n",
    "                        descriptor='haswell',\n",
    "                        order='F'),\n",
    "                     get_filtered(\n",
    "                        get_filters(lang='c'),\n",
    "                        descriptor='haswell',\n",
    "                        order='C'),\n",
    "                    get_filtered(\n",
    "                        get_filters(lang='c'),\n",
    "                        descriptor='haswell',\n",
    "                        order='F')])\n",
    "        \n",
    "\n",
    "namer = compound_namer(order=None, vectype=None)\n",
    "marker = legend_handler(\n",
    "    'order', data_order,\n",
    "    'vectype', vectype_order)\n",
    "\n",
    "\n",
    "plot_data_standard(filtered, namer, marker,\n",
    "    norm=lambda data: normalize_per_key(data, ('lang', 'vectype')),\n",
    "    legend_loc=ll_mid_right,\n",
    "    limits={'y': (0.65, 3)},\n",
    "    figname='source_cvsf.pdf',\n",
    "    stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid vs fixed\n",
    "filtered = combine([\n",
    "    get_filtered(get_filters(),\n",
    "                        platform='intel',\n",
    "                        descriptor='haswell',\n",
    "                        vectype='par',\n",
    "                        vecwidth ='4',\n",
    "                        rates = lambda x: True,\n",
    "                        order='C'),\n",
    "    get_filtered(get_filters(),\n",
    "                        platform='intel',\n",
    "                        descriptor='haswell',\n",
    "                        vectype='w',\n",
    "                        vecwidth ='8',\n",
    "                        rates = lambda x: True,\n",
    "                        order='C')])\n",
    "        \n",
    "\n",
    "namer = compound_namer(order=None, vectype=None)\n",
    "marker = legend_handler(\n",
    "    'rates', ['fixed', 'hybrid'],\n",
    "    'vectype', vectype_order,\n",
    "    num_colors=3)\n",
    "\n",
    "plot_data_standard(filtered, namer, marker,\n",
    "    legend_loc=legend_top,\n",
    "    norm=normalize_per_mech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect of vector width\n",
    "def __get_data(desc, **kwds):\n",
    "    return get_filtered(get_filters(**kwds),\n",
    "                        platform='intel',\n",
    "                        descriptor=desc,\n",
    "                        vectype=lambda x: x in ['w', 'par'],\n",
    "                        vecwidth = lambda x: x in ['4', '8', '16'],\n",
    "                        order='C')\n",
    "        \n",
    "\n",
    "namer = compound_namer(order=None, vectype=None)\n",
    "marker = legend_handler(\n",
    "    'vectype', vectype_order,\n",
    "    'vecwidth', vecwidth_order,\n",
    "    num_colors=3)\n",
    "\n",
    "plot_data_standard(__get_data('haswell'), namer, marker,\n",
    "    norm=normalize_per_mech,\n",
    "    legend_loc=ll_mid_righter_long,\n",
    "    figname='source_vector_width.pdf',\n",
    "    stats=True)\n",
    "\n",
    "plot_data_standard(__get_data('srv2'), namer, marker,\n",
    "    norm=normalize_per_mech,\n",
    "    legend_loc=ll_mid_righter_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NVIDIA\n",
    "def __get_data(desc=['srv2-gpu', 'gpu'], vw=['64', '128'], order='F'):\n",
    "    return get_filtered(\n",
    "        get_filters(cpu=False),\n",
    "        platform='nvidia',\n",
    "        descriptor=lambda x: x in desc,\n",
    "        vecwidth=lambda x: x in vw,\n",
    "        order=order,\n",
    "        vectype='w')\n",
    "\n",
    "namer = compound_namer(descriptor=None, vecwidth=None)\n",
    "marker = legend_handler('descriptor', gpu_desc_order,\n",
    "                       'vecwidth', gpu_vecwidth_order)\n",
    "\n",
    "\n",
    "print('speedup - both')\n",
    "plot_data_gpu_standard(__get_data(), namer, marker,\n",
    "                       norm=normalize_per_mech,\n",
    "                       legend_loc=legend_top,\n",
    "                       figname='gpu_source_speedup.pdf',\n",
    "                       stats=True)\n",
    "\n",
    "namer = compound_namer(**{'mechdata.name': None})\n",
    "marker = legend_handler('mechdata.name', mech_order,\n",
    "                        'vecwidth', gpu_vecwidth_order,\n",
    "                        'descriptor', gpu_desc_order,\n",
    "                        num_colors=4)\n",
    "\n",
    "#c2075\n",
    "print('scaling - srv2')\n",
    "plot_data_gpu_scaling(__get_data(desc=['srv2-gpu'], vw=['128']), namer, marker,\n",
    "                      plot_condition_scaling=True,\n",
    "                      ylog=True,\n",
    "                      xlog=True,\n",
    "                      legend_loc=legend_top)\n",
    " \n",
    "# k40\n",
    "print('scaling - hpc')\n",
    "plot_data_gpu_scaling(__get_data(desc=['gpu'], vw=['128']), namer, marker,\n",
    "                       plot_condition_scaling=True,\n",
    "                       ylog=True,\n",
    "                       xlog=True,\n",
    "                       legend_loc=legend_top,\n",
    "                       figname='gpu_source_scaling.pdf')\n",
    "plot_data_gpu_scaling(__get_data(desc=['gpu'], vw=['128'], order='C'), namer, marker,\n",
    "                       plot_condition_scaling=True,\n",
    "                       ylog=True,\n",
    "                       xlog=True,\n",
    "                       legend_loc=legend_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C vs F on GPU\n",
    "filtered = combine([get_filtered(\n",
    "                        get_filters(cpu=False),\n",
    "                        descriptor=lambda x: 'gpu' in x,\n",
    "                        order='C'),\n",
    "                    get_filtered(\n",
    "                        get_filters(cpu=False),\n",
    "                        descriptor=lambda x: 'gpu' in x,\n",
    "                        order='F')])\n",
    "        \n",
    "namer = compound_namer(order=None, descriptor=None)\n",
    "marker = legend_handler(\n",
    "    'order', data_order,\n",
    "    'descriptor', gpu_desc_order)\n",
    "\n",
    "\n",
    "plot_data_gpu_standard(filtered, namer, marker,\n",
    "    figname='source_gpu_cvsf.pdf',\n",
    "    legend_loc=legend_top,\n",
    "    stats=True)\n",
    "\n",
    "plot_data_gpu_standard(filtered, namer, marker,\n",
    "    norm=lambda data: normalize_per_key(data, 'descriptor'),\n",
    "    legend_loc=legend_top,\n",
    "    stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel scaling efficiency -- source terms\n",
    "def __get_data(desc, vecwidth='8'):\n",
    "    return combine([get_filtered(\n",
    "                       get_filters(),\n",
    "                       platform='intel',\n",
    "                       vectype=lambda x: x in ['w'],\n",
    "                       descriptor=lambda x: x in desc,\n",
    "                       cores=lambda x: True,\n",
    "                       vecwidth=vecwidth),\n",
    "                    get_filtered(\n",
    "                       get_filters(lang='c'),\n",
    "                       descriptor=lambda x: x in desc,\n",
    "                       cores=lambda x: True),\n",
    "                   ])\n",
    "\n",
    "namer = compound_namer(**{'mechdata.name': None, 'vectype':None})\n",
    "marker = legend_handler(\n",
    "    'mechdata.name', mech_order,\n",
    "    'vectype', vectype_order,\n",
    "    num_colors=4)\n",
    "\n",
    "print('haswell - source')\n",
    "plot_data_scaling(__get_data(['haswell']), namer, marker,\n",
    "                  legend_loc=legend_top,\n",
    "                  limits={'y': (2e-1, 1.05),\n",
    "                          'x': (None, 18)},\n",
    "                  figname='source_parallel_scaling.pdf',\n",
    "                  stats=True)\n",
    "\n",
    "plot_data_scaling(__get_data(['haswell']), namer, marker,\n",
    "                  legend_loc=legend_top,\n",
    "                  scale=False,\n",
    "                  limits={'x': (0, 18)},\n",
    "                  ylog=True)\n",
    "\n",
    "print('srv2 - source')\n",
    "plot_data_scaling(__get_data(['srv2'], vecwidth='8'), namer, marker,\n",
    "                  legend_loc=legend_top,\n",
    "                  limits={'y': (4e-1, 1.05),\n",
    "                          'x': (None, 10)})\n",
    "\n",
    "marker = crossover_handler(\n",
    "    'mechdata.name', mech_order,\n",
    "    'vectype', vectype_order,\n",
    "    num_colors=4)\n",
    "plot_data_scaling_crossover(__get_data(['haswell']), namer, marker,\n",
    "                              legend_loc=legend_top,\n",
    "                              ylog=True,\n",
    "                              scale=False,\n",
    "                              limits={'x': (None, 18)},\n",
    "                           figname='source_crossover.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMD efficiency -- source terms\n",
    "def __get_data(desc, vw='8'):\n",
    "    return get_filtered(\n",
    "                       get_filters(),\n",
    "                       platform='intel',\n",
    "                       vectype=lambda x: x in ['w', 'par'],\n",
    "                       descriptor=lambda x: x in desc,\n",
    "                       vecwidth=vw)\n",
    "\n",
    "namer = compound_namer(**{'mechdata.name': None, 'vectype':None})\n",
    "marker = legend_handler(\n",
    "    'mechdata.name', mech_order,\n",
    "    'vectype', vectype_order,\n",
    "    'vectype', vectype_order,\n",
    "    num_colors=4,\n",
    "    sizes=3)\n",
    "\n",
    "print('haswell - source')\n",
    "plot_data_simd(__get_data(['haswell']), namer, marker,\n",
    "              legend_loc=legend_top,\n",
    "              limits={'y': (5.5e-1, None)},\n",
    "              figname='source_simd_efficiency.pdf',\n",
    "              stats=True)\n",
    "\n",
    "print('srv2 - source')\n",
    "plot_data_simd(__get_data(['srv2']), namer, marker,\n",
    "               legend_loc=legend_top,\n",
    "               limits={'y': (None, 1.5)},\n",
    "               figname='source_sse_simd_efficiency.pdf',\n",
    "               stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse vs dense\n",
    "def __get_data(desc):\n",
    "    return combine([get_filtered(\n",
    "                       get_filters(source=False),\n",
    "                       platform='intel',\n",
    "                       vectype='w',\n",
    "                       descriptor=lambda x: x in desc,\n",
    "                       sparse=lambda x: True),\n",
    "                    get_filtered(\n",
    "                       get_filters(source=False, lang='c'),\n",
    "                       descriptor=lambda x: x in desc,\n",
    "                       sparse=lambda x: True)\n",
    "                   ])\n",
    "\n",
    "namer = compound_namer(vectype=None,\n",
    "                       sparse=None,\n",
    "                       descriptor=None)\n",
    "marker = legend_handler(\n",
    "    'sparse', sparse_order,\n",
    "    'vectype', vectype_order\n",
    "    )\n",
    "\n",
    "print('srv2 - langnorm')\n",
    "plot_data_standard(__get_data(['srv2']), namer, marker,\n",
    "                   norm=lambda data: normalize_per_key(data, 'lang'),\n",
    "                   legend_loc=ll_mid_right,\n",
    "                   stats=True)\n",
    "\n",
    "print('srv2 - nonorm')\n",
    "plot_data_standard(__get_data(['srv2']), namer, marker,\n",
    "                   legend_loc=ll_mid_right,\n",
    "                   ylog=True,\n",
    "                   figname='sparse_vs_dense_sse.pdf')\n",
    "\n",
    "plot_data_standard(__get_data(['srv2']), namer, marker,\n",
    "                   norm=lambda data: normalize_per_key(data, 'sparse'),\n",
    "                   legend_loc=ll_mid_right,\n",
    "                   stats=True,\n",
    "                   figname='sparse_vs_dense_see_speedup.pdf')\n",
    "\n",
    "print('haswell - langnorm')\n",
    "plot_data_standard(__get_data(['haswell']), namer, marker,\n",
    "                   norm=lambda data: normalize_per_key(data, 'lang'),\n",
    "                   legend_loc=ll_mid_right,\n",
    "                   \n",
    "                   stats=True)\n",
    "\n",
    "print('haswell - nonorm')\n",
    "plot_data_standard(__get_data(['haswell']), namer, marker,\n",
    "                   legend_loc=ll_mid_right,\n",
    "                   ylog=True,\n",
    "                   figname='sparse_vs_dense.pdf')\n",
    "\n",
    "plot_data_standard(__get_data(['haswell']), namer, marker,\n",
    "                   norm=lambda data: normalize_per_key(data, 'sparse'),\n",
    "                   legend_loc=ll_mid_right,\n",
    "                   stats=True,\n",
    "                   figname='sparse_vs_dense_speedup.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel scaling efficiency -- sparse jacobian\n",
    "def __get_data(desc, sparse=True):\n",
    "    return combine([get_filtered(\n",
    "                       get_filters(source=False, sparse=sparse),\n",
    "                       platform='intel',\n",
    "                       vectype=lambda x: x in ['w'],\n",
    "                       descriptor=lambda x: x in desc,\n",
    "                       cores=lambda x: True),\n",
    "                    get_filtered(\n",
    "                       get_filters(source=False, lang='c', sparse=sparse),\n",
    "                       descriptor=lambda x: x in desc,\n",
    "                       cores=lambda x: True),\n",
    "                   ])\n",
    "\n",
    "namer = compound_namer(**{'mechdata.name': None, 'vectype':None})\n",
    "marker = legend_handler(\n",
    "    'mechdata.name', mech_order,\n",
    "    'vectype', vectype_order,\n",
    "    num_colors=4)\n",
    "\n",
    "# sparse\n",
    "print('sparse haswell')\n",
    "plot_data_scaling(__get_data(['haswell']), namer, marker,\n",
    "                  legend_loc=legend_top,\n",
    "                  limits={'y': (5e-1, 1.05),\n",
    "                          'x': (None, 18)},\n",
    "                  figname='sparse_jac_scaling.pdf',\n",
    "                  stats=True)\n",
    "\n",
    "print('sparse srv2')\n",
    "plot_data_scaling(__get_data(['srv2']), namer, marker,\n",
    "                  legend_loc=legend_top,\n",
    "                  limits={'y': (5e-1, 1.05),\n",
    "                          'x': (None, 9)},\n",
    "                  stats=True)\n",
    "\n",
    "# dense\n",
    "print('dense haswell')\n",
    "plot_data_scaling(__get_data(['haswell'], sparse=False), namer, marker,\n",
    "                  legend_loc=legend_top,\n",
    "                  limits={'y': (0.000000001, 1.05),\n",
    "                          'x': (None, 18)},\n",
    "                  figname='dense_jac_scaling.pdf',\n",
    "                  stats=True)\n",
    "\n",
    "print('dense srv2')\n",
    "plot_data_scaling(__get_data(['srv2'], sparse=False), namer, marker,\n",
    "                  legend_loc=legend_top,\n",
    "                  limits={'y': (3.5e-1, 1.05),\n",
    "                          'x': (None, 9)},\n",
    "                  stats=True)\n",
    "\n",
    "print('crossover sparse haswell')\n",
    "marker = crossover_handler(\n",
    "    'mechdata.name', mech_order,\n",
    "    'vectype', vectype_order,\n",
    "    num_colors=4)\n",
    "plot_data_scaling_crossover(__get_data(['haswell'], sparse=True), namer, marker,\n",
    "                              legend_loc=legend_top,\n",
    "                              ylog=True,\n",
    "                              scale=False,\n",
    "                              limits={'x': (None, 18)})\n",
    "\n",
    "print('crossover dense haswell')\n",
    "plot_data_scaling_crossover(__get_data(['haswell'], sparse=False), namer, marker,\n",
    "                              legend_loc=legend_top,\n",
    "                              ylog=True,\n",
    "                              scale=False,\n",
    "                              limits={'x': (None, 18)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMD efficiency -- sparse jacobian\n",
    "def __get_data(desc, sparse=True):\n",
    "    return combine([get_filtered(\n",
    "                       get_filters(source=False, sparse=sparse),\n",
    "                       platform='intel',\n",
    "                       vectype=lambda x: x in ['w', 'par'],\n",
    "                       descriptor=lambda x: x in desc),\n",
    "                   ])\n",
    "\n",
    "namer = compound_namer(**{'mechdata.name': None, 'vectype':None})\n",
    "marker = legend_handler(\n",
    "    'mechdata.name', mech_order,\n",
    "    'vectype', vectype_order,\n",
    "    num_colors=4)\n",
    "\n",
    "# sparse\n",
    "print('sparse haswell')\n",
    "plot_data_simd(__get_data(['haswell']), namer, marker,\n",
    "                  legend_loc=legend_top,\n",
    "                  figname='sparse_jac_simd_efficiency.pdf')\n",
    "\n",
    "print('sparse srv2')\n",
    "plot_data_simd(__get_data(['srv2']), namer, marker,\n",
    "                  legend_loc=legend_top)\n",
    "\n",
    "# dense\n",
    "print('dense haswell')\n",
    "plot_data_simd(__get_data(['haswell'], sparse=False), namer, marker,\n",
    "                  legend_loc=legend_top,\n",
    "                  figname='dense_jac_scaling_simd_efficiency.pdf')\n",
    "\n",
    "print('dense srv2')\n",
    "plot_data_simd(__get_data(['srv2'], sparse=False), namer, marker,\n",
    "                  legend_loc=legend_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu sparse vs dense\n",
    "# sparse vs dense\n",
    "def __get_data(desc, sparsetest=lambda x: True):\n",
    "    return get_filtered(\n",
    "                       get_filters(source=False, cpu=False),\n",
    "                       platform='nvidia',\n",
    "                       vectype='w',\n",
    "                       descriptor=lambda x: x in desc,\n",
    "                       sparse=sparsetest)\n",
    "\n",
    "namer = compound_namer(sparse=None,\n",
    "                       descriptor=None)\n",
    "marker = legend_handler(\n",
    "    'descriptor', gpu_desc_order,\n",
    "    'sparse', sparse_order,\n",
    "    )\n",
    "\n",
    "\n",
    "plot_data_gpu_standard(__get_data(['srv2-gpu', 'gpu']), namer, marker,\n",
    "    norm=lambda data: normalize_per_key(data, 'sparse'),\n",
    "    figname='gpu_jacobian_speedup.pdf',\n",
    "    legend_loc=legend_top,\n",
    "    stats=True)\n",
    "\n",
    "namer = compound_namer(**{'mechdata.name': None})\n",
    "marker = legend_handler('mechdata.name', mech_order,\n",
    "                        'sparse', sparse_order,\n",
    "                        'mechdata.name', mech_order,\n",
    "                        num_colors=4,\n",
    "                        sizes=4)\n",
    "# plot scaling for both:\n",
    "print('hpc - both')\n",
    "plot_data_gpu_scaling(__get_data(desc=['gpu']), namer, marker,\n",
    "    plot_condition_scaling=True,\n",
    "    ylog=True,\n",
    "    xlog=True,\n",
    "    legend_loc=legend_top,\n",
    "    figname='gpu_sparse_vs_dense.pdf')\n",
    "\n",
    "print('hpc - full')\n",
    "plot_data_gpu_scaling(__get_data(desc=['gpu'], sparsetest=lambda x: x == 'full'), namer, marker, \n",
    "    plot_condition_scaling=True,\n",
    "    ylog=True,\n",
    "    xlog=True,\n",
    "    legend_loc=legend_top)\n",
    "\n",
    "print('srv2 - both')\n",
    "plot_data_gpu_scaling(__get_data(desc=['srv2-gpu']), namer, marker, \n",
    "    plot_condition_scaling=True,\n",
    "    ylog=True,\n",
    "    xlog=True,\n",
    "    legend_loc=legend_top)\n",
    "\n",
    "print('srv2 - full')\n",
    "plot_data_gpu_scaling(__get_data(desc=['srv2-gpu'], sparsetest=lambda x: x == 'full'), namer, marker, \n",
    "    plot_condition_scaling=True,\n",
    "    ylog=True,\n",
    "    xlog=True,\n",
    "    legend_loc=legend_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next intel vs OpenMP\n",
    "def __get_data(desc):\n",
    "    return combine([get_filtered(\n",
    "                       get_filters(source=False),\n",
    "                       platform='intel',\n",
    "                       vectype=lambda x: x in ['w', 'par'],\n",
    "                       descriptor=lambda x: x in desc),\n",
    "                    get_filtered(\n",
    "                       get_filters(source=False, lang='c'),\n",
    "                       descriptor=lambda x: x in desc)\n",
    "                   ])\n",
    "\n",
    "namer = compound_namer(descriptor=None,\n",
    "                       vectype=None)\n",
    "marker = legend_handler(\n",
    "    'descriptor', descriptor_order,\n",
    "    'vectype', vectype_order,\n",
    "    sizes=2\n",
    "    )\n",
    "\n",
    "\n",
    "print('srv2 - sparse')\n",
    "plot_data_standard(__get_data(['srv2']), namer, marker,\n",
    "                   norm=normalize_per_mech)\n",
    "\n",
    "print('haswell - sparse')\n",
    "plot_data_standard(__get_data(['haswell']), namer, marker,\n",
    "                   norm=normalize_per_mech)\n",
    "\n",
    "print('both - sparse')\n",
    "plot_data_standard(__get_data(['haswell', 'srv2']), namer, marker,\n",
    "                   norm=lambda data: normalize_per_key(data, 'descriptor'),\n",
    "                   legend_loc=legend_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next intel vs OpenMP FD vs analytical\n",
    "def __get_data(desc, sparse='sparse'):\n",
    "    return combine([get_filtered(\n",
    "                       get_filters(source=False),\n",
    "                       platform='intel',\n",
    "                       vectype='w',\n",
    "                       rtype='jac',\n",
    "                       sparse=sparse,\n",
    "                       descriptor=lambda x: x in desc),\n",
    "                    get_filtered(\n",
    "                       get_filters(source=False),\n",
    "                       platform='intel',\n",
    "                       vectype='par',\n",
    "                       vecwidth='4',\n",
    "                       rtype='fdjac',\n",
    "                       sparse=sparse,\n",
    "                       descriptor=lambda x: x in desc),\n",
    "                    get_filtered(\n",
    "                       get_filters(source=False, lang='c'),\n",
    "                       rtype=lambda x: 'jac' in x,\n",
    "                       sparse=sparse,\n",
    "                       descriptor=lambda x: x in desc)\n",
    "                   ])\n",
    "\n",
    "namer = compound_namer(descriptor=None,\n",
    "                       vectype=None,\n",
    "                       rtype=None)\n",
    "marker = legend_handler(\n",
    "    'rtype', jac_order,\n",
    "    'vectype', vectype_order,\n",
    "    sizes=2\n",
    "    )\n",
    "\n",
    "\n",
    "plot_data_standard(__get_data(['srv2']), namer, marker,\n",
    "    norm=normalize_per_mech)\n",
    "\n",
    "print('hpc - sparse')\n",
    "plot_data_standard(__get_data(['haswell']), namer, marker,\n",
    "    norm=lambda data: normalize_per_key(data, 'lang'),\n",
    "    figname='finite_difference_vs_analytical.pdf',\n",
    "    legend_loc=legend_top,\n",
    "    ylog=True,\n",
    "    limits = {'y': (0.5, 100),\n",
    "              'x': (0, 900)},\n",
    "    stats=True)\n",
    "\n",
    "print('hpc - dense')\n",
    "plot_data_standard(__get_data(['haswell'], sparse='full'), namer, marker,\n",
    "    norm=lambda data: normalize_per_key(data, 'lang'),\n",
    "    legend_loc=legend_top,\n",
    "    ylog=True,\n",
    "    limits = {'y': (0.5, 350)},\n",
    "    stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu sparse vs dense\n",
    "# sparse vs dense\n",
    "def __get_data(desc, sparse='sparse'):\n",
    "    return get_filtered(\n",
    "                       get_filters(source=False, cpu=False),\n",
    "                       platform='nvidia',\n",
    "                       vectype='w',\n",
    "                       sparse=sparse,\n",
    "                       rtype=lambda x: 'jac' in x,\n",
    "                       descriptor=lambda x: x in desc)\n",
    "\n",
    "namer = compound_namer(rtype=None,\n",
    "                       descriptor=None)\n",
    "marker = legend_handler(\n",
    "    'descriptor', gpu_desc_order,\n",
    "    'rtype', jac_order,\n",
    "    sizes=2\n",
    "    )\n",
    "\n",
    "\n",
    "plot_data_gpu_standard(__get_data(['srv2-gpu', 'gpu']), namer, marker,\n",
    "                       norm=lambda data: normalize_per_key(data, 'descriptor'),\n",
    "                       figname='finite_difference_vs_analytical_gpu.pdf',\n",
    "                       stats=True,\n",
    "                       legend_loc=legend_top)\n",
    "\n",
    "plot_data_gpu_standard(__get_data(['srv2-gpu', 'gpu'], 'full'), namer, marker,\n",
    "                       norm=lambda data: normalize_per_key(data, 'descriptor'),\n",
    "                       stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C vs F\n",
    "# next intel vs OpenMP FD vs analytical\n",
    "def __get_data(desc):\n",
    "    return combine([get_filtered(\n",
    "                       get_filters(source=False),\n",
    "                       platform='intel',\n",
    "                       vectype='w',\n",
    "                       order=lambda x: True,\n",
    "                       descriptor=lambda x: x in desc),\n",
    "                    get_filtered(\n",
    "                       get_filters(source=False, lang='c'),\n",
    "                       order=lambda x: True,\n",
    "                       descriptor=lambda x: x in desc)\n",
    "                   ])\n",
    "\n",
    "namer = compound_namer(descriptor=None,\n",
    "                       vectype=None,\n",
    "                       order=None)\n",
    "marker = legend_handler(\n",
    "    'order', data_order,\n",
    "    'vectype', vectype_order,\n",
    "    sizes=2\n",
    "    )\n",
    "\n",
    "\n",
    "plot_data_standard(__get_data(['srv2']), namer, marker,\n",
    "                   norm=lambda data: normalize_per_key(data, 'lang'))\n",
    "\n",
    "plot_data_standard(__get_data(['haswell']), namer, marker,\n",
    "                   norm=lambda data: normalize_per_key(data, 'lang'))\n",
    "\n",
    "plot_data_standard(__get_data(['haswell', 'srv2']), namer, marker,\n",
    "                   norm=lambda data: normalize_per_key(data, 'descriptor'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu C vs F\n",
    "def __get_data(desc, sparse=True):\n",
    "    return get_filtered(\n",
    "                       get_filters(source=False, cpu=False, sparse=sparse),\n",
    "                       platform='nvidia',\n",
    "                       vectype='w',\n",
    "                       order=lambda x: True,\n",
    "                       descriptor=lambda x: x in desc)\n",
    "\n",
    "namer = compound_namer(order=None,\n",
    "                       descriptor=None)\n",
    "marker = legend_handler(\n",
    "    'order', data_order,\n",
    "    'descriptor', gpu_desc_order,\n",
    "    sizes=2\n",
    "    )\n",
    "\n",
    "\n",
    "plot_data_gpu_standard(__get_data(['srv2-gpu', 'gpu']), namer, marker,\n",
    "    norm=lambda data: normalize_per_key(data, 'descriptor'),\n",
    "    ylog=True)\n",
    "\n",
    "plot_data_gpu_standard(__get_data(['srv2-gpu', 'gpu'], sparse=False), namer, marker,\n",
    "    norm=lambda data: normalize_per_key(data, 'descriptor'),\n",
    "    ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu conp vs conv\n",
    "def __get_data(desc):\n",
    "    return get_filtered(\n",
    "                       get_filters(source=False, cpu=False),\n",
    "                       platform='nvidia',\n",
    "                       vectype='w',\n",
    "                       conp=lambda x: True,\n",
    "                       descriptor=lambda x: x in desc)\n",
    "\n",
    "namer = compound_namer(conp=None,\n",
    "                       descriptor=None)\n",
    "marker = legend_handler(\n",
    "    'conp', conp_order,\n",
    "    'descriptor', gpu_desc_order,\n",
    "    sizes=2\n",
    "    )\n",
    "\n",
    "\n",
    "plot_data_gpu_standard(__get_data(['srv2-gpu', 'gpu']), namer, marker,\n",
    "    norm=lambda data: normalize_per_key(data, 'descriptor'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally pyjac v2 vs v1\n",
    "# it's to manually create the data objects for the old data\n",
    "import os\n",
    "from os.path import join, isdir, isfile\n",
    "import yaml\n",
    "v1_data = join(os.getcwd(), 'pyjac-v1')\n",
    "v2_data = join(os.getcwd(), 'performance')\n",
    "assert isdir(v1_data)\n",
    "assert isdir(v2_data)\n",
    "v1_runs = {}\n",
    "for mech in [join(v1_data, x) for x in os.listdir(v1_data) if isdir(join(v1_data, x))]:\n",
    "    # load data from v2\n",
    "    mbase = os.path.basename(mech)\n",
    "    with open(join(v2_data, mbase, mbase + '.yaml'), 'r') as f:\n",
    "        mech_info = mechdata(**yaml.load(f))\n",
    "    v1_runs[mbase] = []\n",
    "    for file in [join(mech, x) for x in os.listdir(mech) if isfile(join(mech, x)) and x.endswith('.txt')]:\n",
    "        if not '_nco_' in file:\n",
    "            # mechanism\n",
    "            continue\n",
    "        if not '_nosmem_' in file:\n",
    "            continue\n",
    "        with open(file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        mdata = []\n",
    "        for line in lines:\n",
    "            try:\n",
    "                num_cond, runtime = [float(x) for x in line.split(',')]\n",
    "            except:\n",
    "                continue\n",
    "            mdata.append(rundata(num_cond, -1, -1, runtime))\n",
    "        if not len(mdata):\n",
    "            continue\n",
    "        rtype = 'jac' if 'fd' not in file else 'fdjac'\n",
    "        sparse = 'full'\n",
    "        lang = os.path.basename(file).split('_')[0]\n",
    "        vecwidth = '128' if 'cuda' in file else 'False'\n",
    "        order = 'F' if 'cuda' in file else 'C'\n",
    "        vectype = 'w' if 'cuda' in file else 'openmp'\n",
    "        descriptor = 'v1-gpu' if 'cuda' in file else 'v1'\n",
    "        rates = 'hybrid'\n",
    "        kernels = 'fixed'\n",
    "        cores = '1'\n",
    "        conp = 'conp'\n",
    "        platform = 'False'\n",
    "        v1_runs[mbase].append(run(\n",
    "            rtype, sparse, lang, vecwidth, order,\n",
    "            vectype, platform, rates, kernels, cores, conp,\n",
    "            descriptor, mdata, mech_info))\n",
    "        assert not any(isinstance(x, list) for x in v1_runs[mbase])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = combine([get_filtered(\n",
    "                        get_filters(source=False),\n",
    "                        platform='intel',\n",
    "                        vectype='w',\n",
    "                        descriptor='srv2',\n",
    "                        sparse='full'),\n",
    "                    get_filtered(\n",
    "                        get_filters(source=False, lang='c'),\n",
    "                        descriptor='srv2',\n",
    "                        sparse='full'),\n",
    "                    get_filtered(\n",
    "                        get_filters(source=False, lang='c'),\n",
    "                        additional_data=v1_runs,\n",
    "                        descriptor='v1',\n",
    "                        rates='hybrid',\n",
    "                        sparse='full')\n",
    "                    ])\n",
    "\n",
    "namer = compound_namer(descriptor=None, vectype=None)\n",
    "marker = legend_handler('descriptor', ['srv2', 'v1'],\n",
    "                        'vectype', vectype_order,\n",
    "                        sizes=2,\n",
    "                        replacements={r'\\texttt{sse4.2}': r'\\texttt{sse4.2-v2}'})\n",
    "\n",
    "plot_data_standard(filtered, namer, marker,\n",
    "    limits={'y': (1e-3, 1e2)},\n",
    "    ylog=True,\n",
    "    legend_loc=ll_mid_right_long,\n",
    "    figname='v1_vs_v2.pdf',\n",
    "    stats=True)\n",
    "\n",
    "plot_data_standard(filtered, namer, marker,\n",
    "    norm=normalize_per_mech,\n",
    "    legend_loc=legend_top,\n",
    "    stats=True,\n",
    "    ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = combine([get_filtered(\n",
    "                        get_filters(source=False, cpu=False,),\n",
    "                        platform='nvidia',\n",
    "                        vectype='w',\n",
    "                        descriptor='srv2-gpu',\n",
    "                        sparse='full'),\n",
    "                    get_filtered(\n",
    "                        get_filters(source=False, cpu=False),\n",
    "                        lang='cuda',\n",
    "                        additional_data=v1_runs,\n",
    "                        descriptor='v1-gpu',\n",
    "                        rates='hybrid',\n",
    "                        sparse='full')\n",
    "                    ])\n",
    "\n",
    "namer = compound_namer(descriptor=None, vectype=None)\n",
    "marker = legend_handler('descriptor', ['srv2-gpu', 'v1-gpu'],\n",
    "                        'vectype', vectype_order,\n",
    "                        num_colors=2,\n",
    "                        sizes=2,\n",
    "                        replacements={r'\\texttt{C2075}': r'\\texttt{C2075-v2}'})\n",
    "\n",
    "plot_data_gpu_standard(filtered, namer, marker,\n",
    "    ylog=True,\n",
    "    legend_loc=ll_mid_right_long,\n",
    "    figname='v1_vs_v2_gpu.pdf',\n",
    "    stats=True)\n",
    "\n",
    "plot_data_gpu_standard(filtered, namer, marker,\n",
    "    legend_loc=ll_mid_right_long,\n",
    "    norm=normalize_per_mech,\n",
    "    stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve fits\n",
    "def __get_data(desc='haswell', sparse='sparse', source=False):\n",
    "    if source:\n",
    "        sparse = 'full'\n",
    "    return combine([get_filtered(\n",
    "                       get_filters(source=source),\n",
    "                       platform='intel',\n",
    "                       vectype='w',\n",
    "                       sparse=sparse,\n",
    "                       descriptor=lambda x: x in desc),\n",
    "                    get_filtered(\n",
    "                       get_filters(source=source, lang='c'),\n",
    "                       sparse=sparse,\n",
    "                       descriptor=lambda x: x in desc)\n",
    "                   ])\n",
    "\n",
    "def linear(x, a, b):\n",
    "    return a * x ** b\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "def plot_curvefit(*subdata, label=None, marker=None, plot_ind=None):\n",
    "    gp.plot(*subdata, label=label, marker=marker, plot_ind=plot_ind)\n",
    "    marker, hollow, color, size = marker\n",
    "    x, y, z = subdata\n",
    "    popt, pcov = curve_fit(linear, [0] + x, [0] + y)\n",
    "    xrange = np.arange(x[0], x[-1] + 2)\n",
    "    yrange = linear(xrange, *popt)\n",
    "    cname = 'orange' if np.allclose([0.92964400000000003, 0.41147899999999998, 0.145367, 1.0], color) else 'purple'\n",
    "    print(label, cname, popt, pcov)\n",
    "    plt.plot(xrange, yrange, color=color)\n",
    "    \n",
    "namer = compound_namer(descriptor=None,\n",
    "                       vectype=None)\n",
    "marker = legend_handler(\n",
    "    'sparse', sparse_order,\n",
    "    'vectype', vectype_order,\n",
    "    num_colors=2\n",
    "    )\n",
    "\n",
    "print('hpc')\n",
    "plot_data_standard(__get_data(sparse=lambda x: True), namer, marker,\n",
    "    ylog=True,\n",
    "    legend_loc=legend_top,\n",
    "    plotfun=plot_curvefit)\n",
    "\n",
    "print('srv2')\n",
    "plot_data_standard(__get_data(desc='srv2', sparse=lambda x: True), namer, marker,\n",
    "    ylog=True,\n",
    "    legend_loc=legend_top,\n",
    "    plotfun=plot_curvefit)\n",
    "\n",
    "plot_data_standard(__get_data(source=True), namer, marker,\n",
    "    ylog=True,\n",
    "    legend_loc=legend_top,\n",
    "    plotfun=plot_curvefit)\n",
    "\n",
    "plot_data_standard(__get_data(source=True, desc='srv2'), namer, marker,\n",
    "    ylog=True,\n",
    "    legend_loc=legend_top,\n",
    "    plotfun=plot_curvefit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot simd efficiency scaling\n",
    "# it's to manually create the data objects for the scaling data\n",
    "import os\n",
    "import yaml\n",
    "from os.path import join, isdir, isfile\n",
    "data_path = join(os.getcwd(), 'scaling')\n",
    "assert isdir(data_path)\n",
    "scaling_runs = {}\n",
    "mbase = os.path.basename(data_path)\n",
    "for num_reactions in [join(data_path, x) for x in os.listdir(data_path) if isdir(join(data_path, x))]:\n",
    "    # load data from scaling\n",
    "    try:\n",
    "        nr = int(os.path.basename(os.path.normpath(num_reactions)))\n",
    "    except ValueError:\n",
    "        pass\n",
    "    mech_info = {\n",
    "        'mech': '',\n",
    "        'n_reactions': nr,\n",
    "        'n_species': 360,\n",
    "        'n_reversible': -1,\n",
    "        'n_cheb': 0,\n",
    "        'n_plog': 0,\n",
    "        'name': 'IC5H11OH'\n",
    "    }\n",
    "    with open(os.path.join(num_reactions, 'mech.yaml'), 'w') as file:\n",
    "        yaml.dump(mech_info, file, default_flow_style=False)\n",
    "\n",
    "# and load data\n",
    "runs = data_parser.parse_data(rebuild=False, directory=data_path, use_descriptor='haswell')\n",
    "# and move all the runs into a dummy mechanism\n",
    "runs = dict(IC5H11OH=flatten(runs))\n",
    "\n",
    "namer = compound_namer(**{'mechdata.name': None, 'vectype':None})\n",
    "marker = legend_handler(\n",
    "    'mechdata.name', mech_order,\n",
    "    'vectype', vectype_order,\n",
    "    'vectype', vectype_order,\n",
    "    num_colors=0,\n",
    "    sizes=3,\n",
    "    ignore=['IC$_5$H$_{11}$OH'])\n",
    "\n",
    "# and then calculate the scalings\n",
    "plot_data_simd(runs, namer, marker, allow_skip=True,\n",
    "               figname='simd_efficiency_scaling.pdf',\n",
    "               stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
